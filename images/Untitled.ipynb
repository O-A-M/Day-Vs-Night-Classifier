{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day and Night Image Classifier\n",
    "---\n",
    "\n",
    "The day/night image dataset consists of 200 RGB color images in two categories: day and night. There are equal numbers of each example: 100 day images and 100 night images.\n",
    "\n",
    "We're trying to build a classifier that can accurately label these images as day or night, and that relies on finding distinguishing features between the two types of images!\n",
    "\n",
    "*Note: All images come from the [AMOS dataset](http://cs.uky.edu/~jacobs/datasets/amos/) (Archive of Many Outdoor Scenes).*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import resources\n",
    "\n",
    "Before we get started on the project code, import the libraries that we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob #for loading images from a directory\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image data directories\n",
    "image_dir_training = \"images/training/\"\n",
    "image_dir_test = \"images/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the datasets and visualize\n",
    "\n",
    "These first few lines of code will load the training day/night images and store all of them in a variable, `IMAGE_LIST`. This list contains the images and their associated label (\"day\" or \"night\"). \n",
    "\n",
    "For example, the first image-label pair in `IMAGE_LIST` can be accessed by index: \n",
    "``` IMAGE_LIST[0][:]```.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(image_dir):\n",
    "    '''This function loads in images and their labels and places them in a list\n",
    "    im_list[0][:] will be the first image-label pair in the list'''\n",
    "    \n",
    "    im_list = []\n",
    "    image_types = [\"day\", \"night\"]\n",
    "    \n",
    "    # Iterate through each color folder\n",
    "    for im_type in image_types:\n",
    "        \n",
    "        # Iterate through each image file in each image_type folder\n",
    "        # glob reads in any image with the extension \"image_dir/im_type/*\"\n",
    "        for file in glob.glob(os.path.join(image_dir, im_type, \"*\")):\n",
    "            \n",
    "            # Read in the image\n",
    "            im = mpimg.imread(file)\n",
    "            \n",
    "            # Check if the image exists/if it's been correctly read-in\n",
    "            if not im is None:\n",
    "                # Append the image, and it's type (red, green, yellow) to the image list\n",
    "                im_list.append((im, im_type))\n",
    "    \n",
    "    return im_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "IMAGE_LIST = load_dataset(image_dir_training)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preprocess the data input images.\n",
    "\n",
    "This function takes in a list of image-label pairs and outputs a **standardized** list of resized images and numerical labels.\n",
    "1. Resizing every image to a standard size\n",
    "2. Encode the target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_input(image):\n",
    "    \n",
    "    # Resize image and pre-process so that all \"standard\" images are the same size\n",
    "    standard_im = cv2.resize(image, (1100, 600))\n",
    "    \n",
    "    return standard_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(label):\n",
    "    # encode day as 1, night as 0\n",
    "    numerical_val = 0\n",
    "    if(label == 'day'):\n",
    "        numerical_val = 1\n",
    "    \n",
    "    return numerical_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image_list):\n",
    "    \n",
    "    #standardize and encode the input data\n",
    "    standard_list = []\n",
    "    \n",
    "    # Iterate through all the image-label pairs\n",
    "    for item in image_list:\n",
    "        image = item[0]\n",
    "        label = item[1]\n",
    "        \n",
    "        # Standardize the image\n",
    "        standardized_im = standardize_input(image)\n",
    "        \n",
    "        # Create a numerical label\n",
    "        binary_label = encode(label)\n",
    "        \n",
    "        # Append the image, and it's one hot encoded label to the full, processed list of image data\n",
    "        standard_list.append((standardized_im, binary_label))\n",
    "    \n",
    "    return standard_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize all training images\n",
    "STANDARDIZED_LIST = preprocess(IMAGE_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4f3c690bff97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Select an image by index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimage_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mselected_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSTANDARDIZED_LIST\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mselected_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSTANDARDIZED_LIST\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Display a standardized image and its label\n",
    "\n",
    "# Select an image by index\n",
    "image_num = 0\n",
    "selected_image = STANDARDIZED_LIST[image_num][0]\n",
    "selected_label = STANDARDIZED_LIST[image_num][1]\n",
    "\n",
    "# Display image and data about it\n",
    "plt.imshow(selected_image)\n",
    "print(\"Shape: \"+str(selected_image.shape))\n",
    "print(\"Label [1 = day, 0 = night]: \" + str(selected_label))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Feature Extraction\n",
    "\n",
    "Let's try to create a feature that represents the brightness in an image. We'll be extracting the **average brightness** using HSV colorspace. Specifically, we'll use the V channel (a measure of brightness), add up the pixel values in the V channel, then divide that sum by the area of the image to get the average Value of the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the average Value or brightness of an image\n",
    "def avg_brightness(rgb_image):\n",
    "    # Convert image to HSV\n",
    "    hsv = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # Add up all the pixel values in the V channel\n",
    "    sum_brightness = np.sum(hsv[:,:,2])\n",
    "    area = 600*1100.0  # pixels\n",
    "    \n",
    "    # find the avg\n",
    "    avg = sum_brightness/area\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0cd7f0b6d468>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# As an example, a \"night\" image is loaded in and its avg brightness is displayed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mimage_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m190\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtest_im\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSTANDARDIZED_LIST\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_brightness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Testing average brightness levels\n",
    "# Look at a number of different day and night images and think about \n",
    "# what average brightness value separates the two types of images\n",
    "\n",
    "# As an example, a \"night\" image is loaded in and its avg brightness is displayed\n",
    "image_num = 190\n",
    "test_im = STANDARDIZED_LIST[image_num][0]\n",
    "\n",
    "avg = avg_brightness(test_im)\n",
    "print('Avg brightness: ' + str(avg))\n",
    "plt.imshow(test_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build the classifier\n",
    "\n",
    "We'll turn our average brightness feature into a classifier that takes in a standardized image and returns a `predicted_label` for that image. This `estimate_label` function should return a value: 0 or 1 (night or day, respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should take in RGB image input\n",
    "def estimate_label(rgb_image, threshold):\n",
    "    \n",
    "    # Extract average brightness feature from an RGB image \n",
    "    avg = avg_brightness(rgb_image)\n",
    "        \n",
    "    # Use the avg brightness feature to predict a label (0, 1)\n",
    "    predicted_label = 0\n",
    "    #threshold = 120\n",
    "    if(avg > threshold):\n",
    "        # if the average brightness is above the threshold value, we classify it as \"day\"\n",
    "        predicted_label = 1\n",
    "    # else, the pred-cted_label can stay 0 (it is predicted to be \"night\")\n",
    "    \n",
    "    return predicted_label    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the Classifier and Optimize\n",
    "\n",
    "Here is where we test your classification algorithm using our test set of data that we set aside at the beginning of the notebook!\n",
    "Below, we load in the test dataset, standardize it using the `standardize` function you defined above, and then **shuffle** it; this ensures that order will not play a role in testing accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the load_dataset function in helpers.py\n",
    "# Load test data\n",
    "TEST_IMAGE_LIST = load_dataset(image_dir_test)\n",
    "\n",
    "# Standardize the test data\n",
    "STANDARDIZED_TEST_LIST = preprocess(TEST_IMAGE_LIST)\n",
    "\n",
    "# Shuffle the standardized test data\n",
    "random.shuffle(STANDARDIZED_TEST_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructs a list of misclassified images given a list of test images and their labels\n",
    "def get_misclassified_images(test_images, threshold):\n",
    "    # Track misclassified images by placing them into a list\n",
    "    misclassified_images_labels = []\n",
    "\n",
    "    # Iterate through all the test images\n",
    "    # Classify each image and compare to the true label\n",
    "    for image in test_images:\n",
    "\n",
    "        # Get true data\n",
    "        im = image[0]\n",
    "        true_label = image[1]\n",
    "\n",
    "        # Get predicted label from your classifier\n",
    "        predicted_label = estimate_label(im, threshold)\n",
    "\n",
    "        # Compare true and predicted labels \n",
    "        if(predicted_label != true_label):\n",
    "            # If these labels are not equal, the image has been misclassified\n",
    "            misclassified_images_labels.append((im, predicted_label, true_label))\n",
    "            \n",
    "    # Return the list of misclassified [image, predicted_label, true_label] values\n",
    "    return misclassified_images_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2a8cd1edc1fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTANDARDIZED_TEST_LIST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnum_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMISCLASSIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_correct\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# Find all misclassified images in a given test set\n",
    "MISCLASSIFIED = get_misclassified_images(STANDARDIZED_TEST_LIST, threshold=99)\n",
    "\n",
    "# Accuracy calculations\n",
    "total = len(STANDARDIZED_TEST_LIST)\n",
    "num_correct = total - len(MISCLASSIFIED)\n",
    "accuracy = num_correct/total\n",
    "\n",
    "print('Accuracy: ' + str(accuracy))\n",
    "print(\"Number of misclassified images = \" + str(len(MISCLASSIFIED)) +' out of '+ str(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "We received an accuracy of **93.75%** by using only one feature extraction, i.e the average brightness of the image. We could work more on this, for example features that involve the other 2 Hue and Saturation channels to extract more features.\n",
    "This concludes that most simple problems can be solved using traditional image processing, and doesn't need Advanced Deep Learning concepts always.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
